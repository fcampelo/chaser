% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/run_chase.R
\name{run_chase}
\alias{run_chase}
\title{Comparison of Heuristics with Adaptive Sample size Estimation}
\usage{
run_chase(instances, algorithms, dmax, stat = c("mean", "median"),
  method = c("param", "boot", "binom"), alpha = 0.05, nstart = 20,
  nmax = Inf, seed = NULL, ...)
}
\arguments{
\item{instances}{a list object containing lists defining all problem
instances to be used in the experiment.
See \code{Instances and Algorithms} for details.}

\item{algorithms}{a list object containing lists defining all algorithms to
be used in the experiment.
See \code{Instances and Algorithms} for details.}

\item{dmax}{desired confidence interval halfwidth for the estimated mean
performance of each algorithm on each instance.}

\item{stat}{name of statistic for which the CI is desired.}

\item{method}{method used to calculate the interval. Accepts "param" (the
default), "boot" (for bootstrap) or "binom" (for binomial median CI)}

\item{alpha}{significance level for the confidence intervals on the means of
each algo-problem pair.}

\item{nstart}{initial number of algorithm runs.
See \code{Initial Number of Observations} for details.}

\item{nmax}{maximum allowed sample size.}

\item{seed}{seed for the random number generator.
     See \code{Random seed} for details.}

\item{...}{further parameters to be passed on to \code{boot}
         (if method == "boot")}
}
\value{
a list object containing the following items:
\itemize{
   \item \code{data.raw} - data frame containing all observations generated
   \item \code{data.summary} - data frame containing the means, standard
   errors and sample sizes of each algorithm on each problem instance.
}
}
\description{
Run experiment using adaptive sample size estimation.
}
\details{
This routine executes a full experiment using the CHASE method. It
essentially runs each algorithm (i) on each problem instance (j) until the
uncertainty of the estimate of the mean / median performance is below a given
threshold.

The result is an unbalanced experiment, in which the within-instance sample
size is proportional to the variance of the algorithm on that instance, so
that it yields an estimate of mean / median performance with fixed
"measurement error".

Based on this measurement error (which is defined in advance) it is
possible to use standard formulas to calculate the effective sample size
(i.e., the number of problem instances required to achieve a certain
statistical power for a desired effect size) for a given comparative
experiment with metaheuristics (or other algorithms).
}
\section{Instances and Algorithms}{

Parameters \code{instances} and \code{algorithms} must be lists of
\code{instance} (\code{algorithm}) specifications, each defined according to
the following instructions:

Each component of \code{instances} is itself a list containing all relevant
parameters that define the problem instance. Each element
\code{instances[[i]]} must be a named list as defined in the documentation
of function \code{\link{run_nreps}}.

Similarly, the \code{algorithms} parameter must contain a list in which each
element provides the full specification of an algorithm, i.e., a named list
as defined in the documentation of function \code{\link{run_nreps}}
}

\section{Random Seed}{

The \code{seed} argument receives the desired seed for the PRNG, which
can be set for reproducibility purposes. The value of this parameter defaults
to NULL, in which case the seed is arbitrarily set using
\code{as.numeric(Sys.time())}. The value used as seed is always reported in
the output structure.

Notice that this \code{seed} is not passed to the algorithm routines in the
current version.
}

\section{Initial Number of Observations}{

In the general case the initial number of observations / algorithm / instance
(\code{nstart}) should be relatively high (> 20 if outliers are not
expected, > 50 (at least) if that assumption can't be made) to guarantee good
statistical properties (particularly compliance with nominal type-I error
rate \code{alpha}). However, if some distributional assumptions can be
made - particularly low skewness of the population of algorithm results on
the test instances), then \code{nstart} can in principle be as small as 5.

In general, higher sample sizes are the price to pay for abandoning
distributional assumptions. Use lower values of \code{nstart} with caution.
}
\examples{
instances <- list(
list(name = "rnorm sd=1",     xmin = 0, xmax = 1),
list(name = "rnorm sd=4",     xmin = 0, xmax = 1),
list(name = "rnorm sd=16",    xmin = 0, xmax = 1),
list(name = "rexp rate=0.25", xmin = 0, xmax = 1),
list(name = "rexp rate=0.5",  xmin = 0, xmax = 1),
list(name = "rexp rate=1",    xmin = 0, xmax = 1))

algorithms <- list(myalgo = list(name = "distribution.test"))
out <- run_chase(instances, algorithms, dmax = 1, stat = "median", method = "param")
}
\author{
Felipe Campelo (\email{fcampelo@ufmg.br}),
        Fernanda Takahashi (\email{fernandact@ufmg.br})
}

