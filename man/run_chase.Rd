% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/run_chase.R
\name{run_chase}
\alias{run_chase}
\title{Comparison of Heuristics with Adaptive Sample size Estimation}
\usage{
run_chase(instances, algorithms, dmax, alpha = 0.05, nstart = 10,
  nmax = Inf, seed = NULL)
}
\arguments{
\item{instances}{a list object containing lists defining all problem
instances to be used in the experiment.
See \code{Instances and Algorithms} for details.}

\item{algorithms}{a list object containing lists defining all algorithms to
be used in the experiment.
See \code{Instances and Algorithms} for details.}

\item{dmax}{desired confidence interval halfwidth for the estimated mean
performance of each algorithm on each instance.}

\item{alpha}{significance level for the confidence intervals on the means of
each algo-problem pair. Defaults to \code{alpha = 0.05}.}

\item{nstart}{initial number of algorithm runs.
Defaults to \code{nstart = 15}.
See \code{Initial Number of Observations} for details.}

\item{nmax}{maximum allowed sample size. Defaults to \code{nmax = Inf}.}

\item{seed}{seed for the random number generator.
     Defaults to NULL.
     See \code{Random seed} for details.}
}
\value{
a list object containing the following items:
\itemize{
   \item \code{data.raw} - data frame containing all observations generated
   \item \code{data.summary} - data frame containing the means, standard
   errors and sample sizes of each algorithm on each problem instance.
}
}
\description{
Run experiment using adaptive sample size estimation.
}
\details{
This routine executes a full experiment using the CHASE method. It
essentially runs each algorithm (i) on each problem instance (j) until the
uncertainty of the estimate of the mean performance is below a given
threshold.

The result is an unbalanced experiment, in which the within-instance sample
size is proportional to the variance of the algorithm on that instance, so
that it yields an estimate of mean performance with fixed "measurement
error".

Based on this "measurement error" (which is defined in advance) it is
possible to use standard formulas to calculate the effective sample size
(i.e., the number of problem instances required to achieve a certain
statistical power for a desired effect size) for a given comparative
experiment with metaheuristics (or other algorithms).
}
\section{Instances and Algorithms}{

Parameters \code{instances} and \code{algorithms} must lists of
\code{instance} (\code{algorithm}) specifications, each defined according to
the following instructions:

Each component of \code{instances} is itself a list containing all relevant
parameters that define the problem instance. Each element
\code{instances[[i]]} must be a named list as defined in the documentation
of function \code{\link{run_nreps}}.

Similarly, the \code{algorithms} parameter must contain a list in which each
element provides the full specification of an algorithm, i.e., a named list
as defined in the documentation of function \code{\link{run_nreps}}
}

\section{Random Seed}{

The \code{seed} argument receives the desired seed for the PRNG. This value
can be set for reproducibility purposes. The value of this parameter defaults
to NULL, in which case the seed is arbitrarily set using
\code{as.numeric(Sys.time())}. The value used as seed is always reported in
the output structure.

Notice that this \code{seed} is not passed to the algorithm routines in the
current version.
}

\section{Initial Number of Observations}{

In the general case the initial number of observations
(\code{nstart}) should be relatively high (> 15 if outliers are not
expected, > 50 if that assumption can't be made) to guarantee good
statistical properties (particularly compliance with nominal type-I error
rate \code{alpha}). However, if some distributional assumptions can be
made (e.g., low skewness of the population of algorithm results on the test
instances), then \code{nstart} can in principle be as small as 5.

In general, higher sample sizes are the price to pay for abandoning
distributional assumptions. Use lower values of \code{nstart} with caution.
}
\author{
Felipe Campelo (\email{fcampelo@ufmg.br}), Fernanda Takahashi (\email{fernandact@ufmg.br})
}

